---
title: "802 Project Summary"
authors: 
  Maksuda Aktar Toma,
  Jo Charbonneau,
  Ryan Lalicker
date: today
date-format: long
execute: 
  echo: false
  warning: false
format:
  pdf: 
    fig-align: center
    fig-width: 6
    fig-height: 4
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

```{r,  fig.pos="H"}
#| label: data-setup
#| echo: false
#| eval: true

library(knitr)
library(dplyr)
library(ggplot2)
library(naniar)
library(reshape2)
library(GGally)
library(janitor)
library(emmeans)
library(MASS)
library(multcomp)
library(lme4)
library(nnet)
library(tidyr)
library(knitr)
library(kableExtra)
library(corrplot)

data <- read.csv("rptm_simulation.csv")


```

```{r,  fig.pos="H"}
#| label: Scratch-work-1
#| echo: false
#| eval: false

```

# Introduction

This paper summarizes the consulting that was done for our assigned STAT 802 group.
For more information on the experiment, the data, or any other files used in this paper see our [Github page](https://github.com/maksudatoma/Stat-802-Project) which can be found at \<https://github.com/maksudatoma/Stat-802-Project\>.
The coding languages used in the paper are R and SAS.
The corresponding code can be found in *Appendix A - R Code* and *Appendix B - SAS Code* respectively.

# Initial Meetings

The first meeting with our clients was on September 13th.
We discussed their project and what kind of data they were going to be looking at.
They detailed to us their project, which is looking at the levels of Salmonella in beef jerky at different inoculations and thicknesses.
Prior to the meeting they sent us what their variables would be, which gave us a good idea of what might be the best experimental design.
The group informed us they were avoiding a completely randomized design (CRD) at the request of their professor.
With that in mind, we suggested other possible models.

Later, after receiving feedback from Dr. Howard and several PhD students within the statistics department, we suggested adding a time component to the experiment as well as creating multiple batches to replicate each treatment combination.
This lead to us suggested a mixed model for the analysis approach.

In both the initial meeting and the follow-up session the clients were more than happy to implement our suggestions.
In the end the experiment involved two thickness levels (one-fourth and one-eighth of an inch), two inoculation methods (dry and wet), and five evenly spaced time points were measurements were taken (weeks 1-5) creating twenty entries per batch.
The exact number of batches would not be known until after the power analysis, found in the *Power Analysis* section.
We provided the client an example dataset we created to give them a better idea of what the end product may look like.
This dataset had five batches.

# Study Objectives and Proposed Model

The clients were most interested in the effect of the thickness levels, the inoculation method, and their interaction had on the Salmonella levels.
In the final model we included the week effect and subsequent interactions as well.
These variables are the fixed effects in the proposed mixed model.

The other variable included in the experiment is the batch number.
This is therefore treated as a random variable.
As mentioned above, the exact number of batches needed was unknown prior to the power analysis, but five was used as a starting value.

Overall the study employs a 2×2 factorial design with two main factors: Inoculation Method (Dry, Wet) and Thickness (1/4-inch, 1/8-inch).
Repeated measurements are taken over five equally spaced time points (Weeks 1 to 5), allowing the analysis of both main effects, their interaction, and changes over time.

The model can be written in the form

$$
Y_{ijkl} = \mu + \alpha_i + \beta_j + \tau_k + (\alpha \beta)_{ij}+(\alpha \tau)_{ik}+(\beta \tau)_{jk}+(\alpha \beta \tau)_{ijk} + u_l + e_{ijkl}
$$

Here, $Y_{ijkl}$ is the Salmonella level and $\mu$ is the overall mean.
The fixed effects are represented by $\alpha_i$ for the effect of the $i$th inoculation method, $\beta_j$ for the effect of the $j$th thickness level, and $\tau_k$ for the effect of the $k$th week.
The interaction effect of the $i$th inoculation method and the $j$th thickness level is represented by $(\alpha \beta)_{ij}$, with the other two-way interactions following this form.
The three-way interaction between all fixed effects is represented as $(\alpha \beta \tau)_{ijk}$.
The random effect for batches is represented by $u_l$, which we assume are distributed as $u_l$\~$N(0,\sigma_u^2)$.
Lastly, the residuals are represented by $e_{ijkl}$, which we assume can be distributed as $e_{ijkl}$\~$N(0,\sigma^2)$.

# Power Analysis

Before power analysis, We reached out to the client later on in the process to determine what contrasts they were most interested in testing.
They expressed they wanted to see the difference between the two levels of the inoculation method, the two levels of the thickness, and the orthogonal contrasts these variable.
This resulted in six contrasts being tested.

To determine the necessary number of batches needed to increase the likelihood of detecting a true treatment effect, we performed a power analysis.
To do this, probable treatment mean estimates across all five weeks and variance estimates were needed.
The clients provided these metrics from @trtmeans.
We then used these metrics to create a dataset with five batches where the response variable was identical across the batches.
This dataset was then evaluated to determine the power.
The results of the power analysis perfomed in SAS are shown below.

![Results of power analysis.](PowerOutput.png)

The first six rows of the table correspond to the contrasts the clients were interested in testing, while the bottom seven rows are measuring the fixed effects of the model.
Many of the terms have more than 80% power.
Specifically the fixed effects were all high enough for both the clients and ourselves to feel comfortable using five batches.
Two of the orthogonal contrasts, `Dry vs Wet at 1/4 Inches` and `1/4 vs 1/8 inches for Wet inoculation` did have lower power scores, but after talking with both the clients and Dr. Howard about them, we felt comfortable to proceed.

# Simulating Data

After finding the necessary number of batches, which was five, we proceeded with simulating the data.
The estimated treatment means and variances provided by the client were used in the simulation as well.
We then reviewed the simulated dataset for major issues, such as negative response values, and reran the power analysis on the new data set to ensure everything was working properly.
After finding no problems with the dataset, we sent it to the clients.
Note, the simulation was performed in SAS.

# Data Analysis

## Summary Statistics

As part of the project, we analyzed the simulated dataset.
Before fitting out model to the dataset, we first wanted to explore some of the variables.
@fig-sum-stats shows the mean values and standard deviations for each treatment combination.
We can see the changes in mean values are small, so further exploration and analysis are needed.

```{r,,fig.pos="H"}
#| label: fig-sum-stats
#| echo: false
#| eval: true
#| fig-cap: ""

# Summary of response variable across factors and weeks
response_summary <- data %>%
  group_by(Inoculation_Method, Thickness, Week) %>%
  summarise(
    Mean_Response = mean(Response, na.rm = TRUE),
    SD_Response = sd(Response, na.rm = TRUE),
    Count = n()
  )

# Create a summary table using kable
knitr::kable(
  response_summary,
  caption = "Summary of response rariable across factors and weeks",
  digits = 3, # Round numbers to 3 decimal places
  col.names = c("Inoculation Method", "Thickness", "Week", "Mean Response", "SD Response", "Count"),
  format = "markdown"
)


```

## Distribution of response variable

Before continuing our investigation into the relationships among the treatment variables, we want to look into the response variable (Salmonella levels).
Specifically, we want to see how it is distributed.
@fig-hist shows a histogram and Q-Q plot of the response variable in the left and right plots respectively.
While the histogram shows a slight potential skew, this is not enough for us say the distribution is non-normal.
Furthermore, the Q-Q plot indicates the response variable follows a relatively normal distribution.

```{r,,fig.pos="H"}
#| label: fig-hist
#| echo: false
#| eval: true
#| fig-cap: "Plots to see the distribution of the response variable."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Histogram"
#|  - "Q-Q plot"
#| fig-width: 6
#| fig-height: 4


# Basic histogram
ggplot(data, aes(x = Response)) +
  geom_histogram(binwidth = 0.1, color = "black", fill = "skyblue") +
  labs(
    x = "Response",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(text = element_text(size = 14))

ggplot(data, aes(sample = Response)) +
  stat_qq(color = "black") +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal() +
  theme(text = element_text(size = 14))

```

## Exploring the Data

Now we will graphically look at how the different variables of the model impact the response variable.
@fig-explore-1 shows how the mean response variables we saw in @fig-sum-stats change over time, while also controlling for thickness and inoculation method.
Note the y-axis of plot does not start at the origin.
We can see the mean values of samples that used a wet inoculation method (blue lines) tended decrease over time, while samples with the dry inoculation method (red lines) were more of a mixed bag but saw sharp increases between weeks four and five.
The samples cut to 1/8 inches thick (dashed lines) were very similar for most weeks, but diverged near the end of the experiment, while samples cut to 1/4 inches thick (solid lines) did not seem as similar.

```{r,  fig.pos="H"}
#| label: fig-explore-1
#| echo: false
#| eval: true
#| fig-cap: "Line plot of response variable over time, controlling for thickness and inoculation method."
#| fig-width: 6
#| fig-height: 4

ggplot(response_summary, aes(x = Week, y = Mean_Response, color = Inoculation_Method, group = interaction(Inoculation_Method, Thickness))) +
  geom_line(aes(linetype = Thickness), size = 1) +
  geom_point(size = 2) +
  labs(
    x = "Week",
    y = "Mean Response",
    color = "Inoculation Method",
    linetype = "Thickness"
  ) +
  theme_minimal() +
  theme(
    text = element_text(size = 14),
    legend.position = "bottom"
  )

```

Another element to consider is correlation over time.
Since this is a repeated measures experiment we need to account for this correlation by selecting a type of covariance structure.
There are several types of structures such as variance components (VC), unstructured (UN), compound symmetry (CS) and heterogeneous compound symmetry (CSH), $p$-order auto-regressive (AR($p$)) and heterogeneous auto-regressive (ARH($p$)), $p$-order ante-dependence (ANTE($p$)), and Toeplitz (TOEP) among others.
For more information on these see @purdue and @usdacov.
The AR($p$) structure fits data that is ordered through time an equally spaced.
For that reason, our initial plan was to use this as the covariance structure with $p=1$.

To see if this first-order auto-regressive structure might fit the data, let's consider the table and plot in @fig-corr.
The correlation matrix (left) and plot (right) show the relationships between repeated measurements over weeks one to five.
Strong correlations are observed between adjacent weeks (e.g., Week 1 vs. Week 2, r=0.69, Week 2 vs. Week 3, r=0.74), indicating temporal dependency.
Correlations weaken as the time gap increases (e.g., Week 1 vs. Week 5, r=0.29), leading us to believe orders of $p>1$ are not necessary.
This can be seen visually in the plot which uses circle size and color to model the correlation metrics seen in the matrix.
We can see as the gap between weeks increases, the circles become smaller and lighter.
This pattern supports the use of models like AR($1$).

```{r,,fig.pos="H"}
#| label: fig-corr
#| echo: false
#| eval: true
#| fig-cap: "Table and plots to see the correlation across time."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Correlation matrix"
#|  - "Correlation plot"
#| fig-width: 6
#| fig-height: 4

wide_data <- pivot_wider(data, names_from = Week, values_from = Response)

# Remove non-numeric columns (like ID or group factors)
time_data <- wide_data[ , -1] # Exclude the first column (ID or grouping variable)
time_data <- time_data[sapply(time_data, is.numeric)]

# Compute the correlation matrix across time points
time_cor_matrix <- cor(time_data, use = "pairwise.complete.obs")

cor_df <- as.data.frame(time_cor_matrix)
cor_df <- cbind(Time = rownames(cor_df), cor_df)

kable(
  cor_df,
  digits = 2,
  col.names = c("Time", colnames(time_cor_matrix)))
  

corrplot(time_cor_matrix, method = "circle", type = "upper", tl.col = "black", tl.srt = 45)

```

## Model Comparison

After exploring the data we can move on to fitting the model.
While we were confident in using the AR($1$), we chose to fit the model using other covariance structures as well so we could see how the fit compares.
The results are shown in @fig-model-comparison-table.
For each of the fit statistics in this table a lower score is better, even when looking at negative values.
(@Statology).
This means the model fit using an AR($1$) structure had the best AIC and AICC scores and a respectable BIC score.
This verifies our choice in the AR($1$) covariance structure.

```{r, fig.pos="H"}
#| label: fig-model-comparison-table
#| echo: false
#| eval: true
#| fig-cap: "Model comparison table."

# Model comparison data
covstruct <- data.frame(
  Model = c("VC", "UN", "CS", "AR(1)", "ARH(1)", "ANTE(1)", "TOEP"),
  AIC = c(-12.25, -12.22, -11.6, -12.86, -12.56, -8.57, -7.34),
  AICC = c(-12.09, -3.58, -11.29, -12.55, -11.01, -5.39, -6.19),
  BIC = c(-13.03, -18.47, -12.77, -14.03, -15.30, -12.48, -9.68)
)

knitr::kable(
  covstruct,
  format = "markdown",
  align = "c"
)

```

After verifying the fit of the AR($1$) covariance structure for the repeated measures, we needed to see if the assumptions for a linear mixed model were violated or not.
These include the residuals being normally distributed and homogeneous.
The plots below allow us to evaluate these assumptions.
To graphically test normality, we can look at both the histogram (top right) and the Q-Q plot (bottom left).
These both appear approximately normal, indicating the assumption holds.
The boxplot (bottom right) can also show normality as well as potential outliers.
It appears there is one outlier, but the normallity assmption still holds.
The residual plot (top left) allows us to check if the homogeneous assumption holds, and it appears to since the points seem somewhat randomly distributed with no clear pattern.
Since the assumptions are holding, we can proceed with the linear mixed model.

![Residual plots for checking assumptions.](ar-4.png){width="4in"}

# Model Output

PROC GLIMMIX was implemented in SAS where reponse variable (y) is Gaussian and the link function used is ‘identity’. The ‘class level information’ table displays the number of levels and their values in the dataset for categorical
variables.The model successfully converges. Various model fit statistics are produced.

![Fig](ar-1'.png)

Below are three tables from the SAS output.  The first is the *Fit Statistics* table, which is where the metrics used in @fig-model-comparison-table come from.  The *Covariance Parameter Estimates* table shows how much of the variance in the model is explained by the random terms.  The *Type III Tests of Fixed Effects* table allows us to see if the fixed effects and/or their interactions are significant by looking at the p-values reported in the `PR > F` column. 

The model successfully converged, and various model fit statistics are provided. The table of ‘Covariance Parameter Estimates’ provides the estimates for the variance components in the model. The estimated variance for the random intercept (batches) is 0.03802, with a standard error of 0.02755. The estimate for the AR(1) autocorrelation structure is -0.2140, capturing the weak negative correlation between adjacent time points. Lastly, the residual variance is estimated as 0.02064, with a standard error of 0.004423. These estimates quantify the variability in the model across batches, within-subject repeated measures, and unexplained residual variability.

Among the fixed effects, Inoculation_Method (p=0.0286), Thickness (p<0.0001), and Week (p=0.0216) significantly influence the response, with notable interactions between Inoculation_Method*Thickness (p<0.0001) and Thickness*Week (p=0.0006), highlighting combined effects. However, the interactions Inoculation_Method*Week (p=0.1529) and Inoculation_MethodThicknessWeek (p=0.6970) are not significant, suggesting they do not substantially impact the response.

Overall, we can say that the method of inoculation, the thickness of the beef jerky, and the week of measurement all have significant effects on the outcome. Additionally, the way the method of inoculation and thickness work together plays an important role, as does how thickness changes over time. However, the combination of all three factors (inoculation method, thickness, and week) does not appear to have a meaningful impact.

![*Fit Statistics*, *Covariance Parameter Estimates*, and *Type III Tests of Fixed Effects* tables.](ar-1.png){width=3.5in}
This table shows the least squares means (LSMeans) for combinations of Inoculation_Method, Thickness, and Week, representing the estimated response for each factor combination (e.g., "Dry, 1/4-inch, Week 1"). The estimates are highly significant (p<0.0001) for all combinations, with confidence intervals providing ranges for each mean. Key statistics include the standard error, degrees of freedom, t-values, and p-values, reflecting the precision and significance of the estimates.

**Easy Interpretation for client**
The table summarizes how the response variable changes across combinations of inoculation methods, material thickness, and weeks. For example, for the 1/4-inch thickness, both Dry and Wet methods show increases over time, but the Dry method typically has higher responses. Similarly, for the 1/8-inch thickness, the differences between Dry and Wet methods are smaller but still present. Confidence intervals provide assurance about the reliability of these estimates, and all results are statistically significant, confirming the trends observed.

![LS Means table.](ar-3.png){width=5in}

This output provides detailed results for the interaction of Inoculation_Method and Thickness. The least squares means (LSMeans) indicate that for both Dry and Wet inoculation methods, 1/8-inch thickness has significantly higher responses compared to 1/4-inch thickness (p<0.0001). Pairwise comparisons confirm significant differences, such as Dry 1/4-inch vs. 1/8-inch (p<0.0001) and Wet 1/4-inch vs. 1/8-inch (p=0.0209). Differences between inoculation methods (e.g., Dry 1/4-inch vs. Wet 1/4-inch) are also significant, with Wet showing slightly higher means. These findings highlight strong interaction effects, emphasizing that the relationship between inoculation method and response varies depending on the material thickness.

Overall, both the inoculation method (Dry or Wet) and the thickness (1/4-inch or 1/8-inch) significantly affect the outcome, and these effects depend on each other. For both methods, the 1/8-inch thickness consistently leads to higher responses compared to 1/4-inch thickness. When comparing Dry and Wet methods, Wet generally performs slightly better, especially for 1/4-inch thickness. However, the differences between Dry and Wet are more noticeable at 1/8-inch thickness, highlighting that the combination of method and thickness plays a key role. These findings suggest that to optimize results, we need to carefully consider the interaction between the method used and the thickness of the material.

![fig](ar-5.png)

**NOTE: Should we show other two way significant interaction as well like this?**





```{r, fig.pos="H"}
#| label: fig-simple-effects
#| echo: false
#| eval: true
#| fig-cap: ""

```

**Write down the model structure**

![Contrasts table.](ar-2.png){width="3.5in"}

# Conclusion

# Future Work

\newpage

# References

::: {#refs}
:::

\newpage

# Appendix A - R Code

```{r,  fig.pos="H"}
#| label: appendix A
#| echo: true
#| eval: false

```

\newpage

# Appendix B - SAS Code

### Power Analysis

``` sas
data rptm_means;
input Inoculation_Method $ Thickness $ @@; 
do Week=1 to 5 by 1; 
    input mu @@; 
    output; 
end;
datalines;
Dry 1/4 4.26 4.25 4.47 4.33 4.54
Dry 1/8 4.91 4.95 4.67 4.56 4.97
Wet 1/4 4.21 4.57 4.65 4.49 4.38
Wet 1/8 4.86 4.78 4.62 4.32 4.22
;

data rptm_design;
 set rptm_means;
 do Batches = 1 to 5; /* Creating 3 blocks (batches) */
  output;
 end;
run;

proc print data=rptm_design;
run;

/* Creating Model */

proc glimmix data=rptm_design;
    class Batches Inoculation_Method Thickness Week;
    model mu = Inoculation_Method|Thickness|Week;
    random intercept / subject=Batches;
    random Week / subject=Batches*Inoculation_Method*Thickness type=ar(1) residual;
    parms (.029)(0.017)(.028)/hold=1,2,3;  
    /* Provide 3 parameters for variance components */
    lsmeans Inoculation_Method*Thickness*Week / slicediff=Week cl;
    /* Define main effect contrasts */
    contrast 'Dry vs Wet' 
        Inoculation_Method 1 -1;
    contrast '1/4 vs 1/8 inches' 
        Thickness 1 -1;

    /* Define interaction contrasts */
   contrast 'Dry vs Wet at 1/4 Inches' 
        Inoculation_Method 1 -1 Inoculation_Method*Thickness 1 0 -1 0; 
    contrast 'Dry vs Wet at 1/8 Inches' 
        Inoculation_Method 1 -1 Inoculation_Method*Thickness 0 1 0 -1; 
    contrast '1/4 vs 1/8 inches for Dry inoculation'
        Thickness 1 -1 Inoculation_Method*Thickness 1 -1 0 0;
    contrast '1/4 vs 1/8 inches for Wet inoculation'
        Thickness 1 -1 Inoculation_Method*Thickness 0 0 1 -1;
               
    ods output contrasts=f_contrast tests3=f_anova;
run;

/*Power*/
data power;
    set f_contrast f_anova;
    ncparm = numdf * fvalue;
    alpha = 0.05;
    fcrit = finv(1-alpha, numdf, dendf, 0);
    power = 1 - probf(fcrit, numdf, dendf, ncparm);
run;

proc print data=power;
run;
```

### Simulation

``` sas
/* Step 1: Define AR(1) Covariance Structure in PROC IML */
proc iml;
    n = 20;                    /* Number of subjects per treatment*/
    mean = {0 0 0 0 0};        /* Mean for each week */
    T = 5;                     /* Number of repeated measures (weeks) */
    rho = 0.2;                 /* AR(1) correlation parameter */
    sigma2 = {0.29 0.29 0.29 0.29 0.29};      /* Variance for each week */
    
    /* Construct AR(1) covariance matrix */
    cov = j(T, T, 0);
    do i = 1 to T;
        do j = 1 to T;
            cov[i, j] = sqrt(sigma2[i] * sigma2[j]) * rho**abs(i - j);
        end;
    end;
    
    /* Print covariance matrix */
    print "Covariance Matrix:", cov;

    /* Generate simulated data using the covariance matrix */
    call randseed(12349);      /* Set random seed */
    x = randnormal(n, mean, cov); /* Simulate AR(1) correlated data */
    cname = {"t1", "t2", "t3", "t4", "t5"};
    
    /* Print the simulated data matrix directly */
    print "Simulated Data Matrix (x):", x;
    /* Print Sample mean */
    samplemean = x[:,];
    print samplemean n;

    /* Create dataset from simulated data */
    create inputdatacb from x[colname=cname];
    append from x;
close inputdatacb;
quit;

/* Step 2: Display the Simulated Data as a SAS Table */
proc print data=inputdatacb label;
    title "Simulated Data with AR(1) Covariance Structure";
run;

/* Step 3: Define Treatment Structure and Random Effects */
data rptm_simulation;
    retain Subject 0;
    keep Inoculation_Method Thickness Week Batches Response;

    array weeks[5] t1-t5;

    /* Define mean values for each combination of factors and week */
    if _n_ = 1 then do;
        array mean_values[4,2,5] _temporary_ (
            /* Dry, 1/4 inch */
            4.26, 4.25, 4.47, 4.33, 4.54,
            /* Dry, 1/8 inch */
            4.91, 4.95, 4.67, 4.56, 4.97,
            /* Wet, 1/4 inch */
            4.21, 4.57, 4.65, 4.49, 4.38,
            /* Wet, 1/8 inch */
            4.86, 4.78, 4.62, 4.32, 4.22
        );
    end;

    /* Simulation parameters */
    sigma_batch = sqrt(0.029); /* Batch variance */
    sigma_resid = sqrt(0.017); /* Residual variance */

    /* Loop through each combination of factors */
    do Batches = 1 to 5; /* Number of batches */
        batch_effect = rand("Normal", 0, sigma_batch); /*Random batch effect*/

        do Inoculation_Method = "Dry", "Wet";
            do Thickness = "1/4-inch", "1/8-inch";
                Subject + 1;
                set inputdatacb;

                /* Generate response for each week with AR(1) structure */
                do Week = 1 to 5;
                    Mean_Value = mean_values[
                      (Inoculation_Method="Dry")*1+(Inoculation_Method="Wet")*2,
                      (Thickness="1/4-inch")*1 + (Thickness="1/8-inch")*2,
                        Week
                    ];
                    Response = Mean_Value + batch_effect + weeks[Week];
                    output;
                end;
            end;
        end;
    end;
run;

/* Step 4: Display the Simulated Data in a Structured Format */
proc print data=rptm_simulation label;
    title "Simulated Data for 2x2 Factorial Design with Repeated Measures";
run;
```

### Analysis

``` sas
proc glimmix data=data plots=residualpanel;
    class Batches Inoculation_Method Thickness Week;
    model Response = Inoculation_Method|Thickness|Week;
    random intercept / subject=Batches;
    random Week / subject=Batches*Inoculation_Method*Thickness type=ar(1) residual;
    lsmeans Inoculation_Method*Thickness*Week / adjust=tukey cl;
    
    /* Define main effect contrasts */
    contrast 'Dry vs Wet' 
        Inoculation_Method 1 -1;
    contrast '1/4 vs 1/8 inches' 
        Thickness 1 -1;

    /* Define interaction contrasts */
   contrast 'Dry vs Wet at 1/4 Inches' 
        Inoculation_Method 1 -1 Inoculation_Method*Thickness 1 0 -1 0; 
    contrast 'Dry vs Wet at 1/8 Inches' 
        Inoculation_Method 1 -1 Inoculation_Method*Thickness 0 1 0 -1; 
    contrast '1/4 vs 1/8 inches for Dry inoculation'
        Thickness 1 -1 Inoculation_Method*Thickness 1 -1 0 0;
    contrast '1/4 vs 1/8 inches for Wet inoculation'
        Thickness 1 -1 Inoculation_Method*Thickness 0 0 1 -1;
               
    ods output contrasts=f_contrast tests3=f_anova;
run;
```
